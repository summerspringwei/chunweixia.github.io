@article{10.1145/3368305,
author = {Xia, Chunwei and Zhao, Jiacheng and Cui, Huimin and Feng, Xiaobing and Xue, Jingling},
title = {DNNTune: Automatic Benchmarking DNN Models for Mobile-cloud Computing},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3368305},
doi = {10.1145/3368305},
abstract = {Deep Neural Networks (DNNs) are now increasingly adopted in a variety of Artificial Intelligence (AI) applications. Meantime, more and more DNNs are moving from cloud to the mobile devices, as emerging AI chips are integrated into mobiles. Therefore, the DNN models can be deployed in the cloud, on the mobile devices, or even mobile-cloud coordinate processing, making it a big challenge to select an optimal deployment strategy under specific objectives.This article proposes a DNN tuning framework, i.e., DNNTune, that can provide layer-wise behavior analysis across a number of platforms. Using DNNTune, this article further selects 13 representative DNN models, including CNN, LSTM, and MLP, and three mobile devices ranging from low-end to high-end, and two AI accelerator chips to characterize the DNN models on these devices to further assist users finding opportunities for mobile-cloud coordinate computing. Our experimental results demonstrate that DNNTune can find a coordinated deployment achieving up to 1.66\texttimes{} speedup and 15\texttimes{} energy saving comparing with mobile-only and cloud-only deployment.},
journal = {ACM Trans. Archit. Code Optim.},
month = dec,
articleno = {49},
numpages = {26},
keywords = {mobile-cloud computing, heterogeneous computing, DNN}
}