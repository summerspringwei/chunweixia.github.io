@inproceedings{zhang-etal-2024-introducing,
    title = "Introducing Compiler Semantics into Large Language Models as Programming Language Translators: A Case Study of {C} to x86 Assembly",
    author = "Zhang, Shuoming  and
      Zhao, Jiacheng  and
      Xia, Chunwei  and
      Wang, Zheng  and
      Chen, Yunji  and
      Cui, Huimin",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.55/",
    doi = "10.18653/v1/2024.findings-emnlp.55",
    pages = "996--1011",
    abstract = "Compilers are complex software containing millions of lines of code, taking years to develop. This paper investigates to what extent Large Language Models (LLMs) can replace hand-crafted compilers in translating high-level programming languages to machine instructions, using C to x86 assembly as a case study. We identify two challenges of using LLMs for code translation and introduce two novel data pre-processing techniques to address the challenges: numerical value conversion and training data resampling. While only using a 13B model, our approach achieves a behavioral accuracy of over 91{\%}, outperforming the much larger GPT-4 Turbo model by over 50{\%}. Our results are encouraging, showing that LLMs have the potential to transform how compilation tools are constructed."
}
