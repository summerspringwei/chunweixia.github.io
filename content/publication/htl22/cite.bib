@article{xia2022hope,
  author    = {Xia Chunwei and Zhao Jiacheng and Cui Huimin and Feng Xiaobing},
  title     = {{HOPE: a heterogeneity-oriented parallel execution engine for inference on mobiles}},
  journal   = {High Technology Letters (English Edition)},
  year      = {2022},
  volume    = {28},
  number    = {4},
  pages     = {363--372},
  doi       = {10.3772/j.issn.1006-6748.2022.04.004},
  keywords  = {deep neural network (DNN), mobile, heterogeneous scheduler, parallel computing},
  abstract  = {It is significant to efficiently support artificial intelligence (AI) applications on heterogeneous mobile platforms, especially coordinately execute a deep neural network (DNN) model on multiple computing devices of one mobile platform. This paper proposes HOPE, an end-to-end heterogeneous inference framework running on mobile platforms to distribute the operators in a DNN model to different computing devices. The problem is formalized into an integer linear programming (ILP) problem and a heuristic algorithm is proposed to determine the near-optimal heterogeneous execution plan. The experimental results demonstrate that HOPE can reduce up to 36.2% inference latency (with an average of 22.0%) than MOSAIC, 22.0% (with an average of 10.2%) than StarPU and 41.8% (with an average of 18.4%) than Î¼Layer respectively.},
  language  = {English}
}
